import threading
import queue
import time
from typing import Dict, List, Optional, Tuple

class DuckDBConnectionPool:
    def __init__(self, role_arn: str, region: str, max_connections: int = 10, cache_size_mb: int = 2000):
        """Initialize a connection pool for DuckDB connections."""
        self.role_arn = role_arn
        self.region = region
        self.cache_size_mb = cache_size_mb
        self.max_connections = max_connections
        self.sts_manager = STSManager(role_arn, region)
        
        # Connection pool implemented as a queue
        self.pool = queue.Queue(maxsize=max_connections)
        
        # Initialize the pool with connections
        for _ in range(max_connections):
            conn = self._create_new_connection()
            self.pool.put(conn)
            
        self.active_connections = 0
        self._lock = threading.Lock()
        logger.info(f"Initialized DuckDB connection pool with {max_connections} connections")
        
    def _create_new_connection(self):
        """Create a new DuckDB connection with proper setup."""
        try:
            conn = duckdb.connect(database=':memory:')
            conn.install_extension(f"{model_zip_folder}/httpfs.duckdb_extension")
            conn.execute("LOAD httpfs")
            conn.execute(f"SET memory_limit='{self.cache_size_mb}MB'")
            conn.execute("SET enable_object_cache=true")
            
            # Set initial credentials
            self._update_connection_credentials(conn)
            return conn
        except Exception as e:
            logger.error(f"Failed to create DuckDB connection: {str(e)}")
            raise
    
    def _update_connection_credentials(self, conn):
        """Update AWS credentials for a specific connection."""
        credentials = self.sts_manager.get_credentials()
        conn.execute(f"SET s3_region='{self.region}'")
        conn.execute(f"SET s3_access_key_id='{credentials['aws_access_key_id']}'")
        conn.execute(f"SET s3_secret_access_key='{credentials['aws_secret_access_key']}'")
        conn.execute(f"SET s3_session_token='{credentials['aws_session_token']}'")
    
    def get_connection(self, timeout: int = 5):
        """Get a connection from the pool with timeout."""
        try:
            # Try to get a connection from the pool
            conn = self.pool.get(block=True, timeout=timeout)
            with self._lock:
                self.active_connections += 1
            logger.debug(f"Got connection from pool. Active: {self.active_connections}")
            
            # Update credentials before returning
            self._update_connection_credentials(conn)
            return conn
        except queue.Empty:
            logger.warning("Connection pool timeout - all connections in use")
            raise RuntimeError("No database connections available")
    
    def return_connection(self, conn):
        """Return a connection to the pool."""
        try:
            # Simple validation to check connection is still usable
            conn.execute("SELECT 1").fetchone()
            self.pool.put(conn)
            with self._lock:
                self.active_connections -= 1
            logger.debug(f"Returned connection to pool. Active: {self.active_connections}")
        except Exception as e:
            logger.warning(f"Discarding broken connection: {str(e)}")
            # Create a new connection to replace the broken one
            with self._lock:
                self.active_connections -= 1
            new_conn = self._create_new_connection()
            self.pool.put(new_conn)
    
    def execute_query(self, query: str, params: Optional[Dict] = None) -> Tuple[pd.DataFrame, Dict]:
        """Execute a query using a connection from the pool."""
        conn = None
        start_time = time.time()
        thread_id = threading.get_ident()
        
        try:
            # Get connection from pool
            conn = self.get_connection()
            
            # Execute query
            logger.debug(f"[Thread-{thread_id}] Executing query: {query}")
            if params:
                result = conn.execute(query, params).df()
            else:
                result = conn.execute(query).df()
            
            query_time = time.time() - start_time
            metrics = {"query_time_ms": round(query_time * 1000, 2)}
            
            logger.debug(f"[Thread-{thread_id}] Query completed in {metrics['query_time_ms']}ms")
            return result, metrics
            
        except Exception as e:
            logger.error(f"[Thread-{thread_id}] Query execution failed: {str(e)}")
            raise
        finally:
            # Always return the connection to the pool if we got one
            if conn:
                self.return_connection(conn)
    
    def cleanup(self):
        """Close all connections in the pool."""
        while not self.pool.empty():
            try:
                conn = self.pool.get(block=False)
                conn.close()
            except queue.Empty:
                break
            except Exception as e:
                logger.error(f"Error closing connection: {str(e)}")
        logger.info("Connection pool cleaned up")


# Create a connection pool instead of a single manager
db_pool = DuckDBConnectionPool(
    role_arn=config['role_arn'],
    region=config['region'],
    max_connections=THREAD_POOL_SIZE + 2  # A few extra connections for safety
)

# Replace the execute_query function to use the pool
def execute_query(query: str, params: Optional[Dict] = None) -> pd.DataFrame:
    """Execute a query using the connection pool."""
    try:
        result, metrics = db_pool.execute_query(query, params)
        logger.info(f"Query metrics: {metrics}")
      
        if not result.empty:
            return result
        else:
            logger.warning("Query returned empty result")
            return pd.DataFrame()
    except Exception as e:
        logger.error(f"Error executing query: {str(e)}")
        raise

# Add to cleanup function
def cleanup():
    """Clean up resources when application is shutting down."""
    logger.info("Shutting down application and cleaning up resources")
    thread_pool.shutdown(wait=True)
    db_pool.cleanup()
    logger.info("Resources cleaned up successfully")
